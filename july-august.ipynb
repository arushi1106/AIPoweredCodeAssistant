{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T17:23:44.376330Z",
     "start_time": "2025-08-01T17:23:44.365043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re"
   ],
   "id": "b166dcb8cb5622ce",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T17:24:45.247446Z",
     "start_time": "2025-08-01T17:24:44.988832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key= \"API KEY\")"
   ],
   "id": "f5a184aa7d9999b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T17:24:59.426907Z",
     "start_time": "2025-08-01T17:24:59.064915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the full dataset\n",
    "df = pd.read_csv(\"/Users/arushijain/PycharmProjects/AIPoweredCodeAssistant/datasets/security/test_preprocessed.csv\")"
   ],
   "id": "616f3d81f4a98361",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T17:25:14.109045Z",
     "start_time": "2025-08-01T17:25:14.104441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Store outputs\n",
    "llm_outputs = []"
   ],
   "id": "fefcfe1b7dec0cfe",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T17:25:29.487307Z",
     "start_time": "2025-08-01T17:25:29.478111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prompt template\n",
    "def create_prompt(code_snippet):\n",
    "    return f\"\"\"\n",
    "You are a security auditor. Analyze the following C code and determine whether it contains any security vulnerabilities (such as buffer overflow, memory leaks, use-after-free, or unsafe pointer manipulation). If yes, explain what they are. If not, state it's safe.\n",
    "\n",
    "Code:\n",
    "{code_snippet}\n",
    "\n",
    "Answer with one of the following:\n",
    "- 'VULNERABLE' and the reason\n",
    "- 'SAFE' and why\n",
    "\"\"\""
   ],
   "id": "1cc53b5dc7314f9",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T17:26:45.093050Z",
     "start_time": "2025-08-01T17:26:45.082676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM query function\n",
    "def get_llm_response(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature = 0\n",
    "        )\n",
    "        completion = response.choices[0].message.content\n",
    "        return completion\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\""
   ],
   "id": "5f67513a83eaebc",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T00:22:23.921155Z",
     "start_time": "2025-08-01T17:27:00.822697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through the entire dataset\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    code = row['func']\n",
    "    target = row['target']\n",
    "    prompt = create_prompt(code)\n",
    "    response = get_llm_response(prompt)\n",
    "\n",
    "    # Add short delay to avoid rate limiting\n",
    "    time.sleep(1.5)\n",
    "\n",
    "    # Parse prediction from response using regex\n",
    "    match = re.search(r\"\\b(SAFE|VULNERABLE)\\b\", response.upper())\n",
    "    pred = match.group(1) if match else \"UNKNOWN\"\n",
    "\n",
    "    llm_outputs.append({\n",
    "        \"id\": row['id'],\n",
    "        \"true_label\": \"VULNERABLE\" if target else \"SAFE\",\n",
    "        \"llm_pred\": pred,\n",
    "        \"response\": response\n",
    "    })"
   ],
   "id": "52c10917357cdd0c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [6:55:22<00:00,  9.12s/it]      \n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T00:22:28.088566Z",
     "start_time": "2025-08-02T00:22:27.526705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(llm_outputs)\n",
    "results_df.to_csv(\"llm_vulnerability_results_full.csv\", index=False)"
   ],
   "id": "f2b7bd204541e34d",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T00:22:30.285134Z",
     "start_time": "2025-08-02T00:22:30.088496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print accuracy\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "valid_results = results_df[results_df['llm_pred'].isin([\"SAFE\", \"VULNERABLE\"])]\n",
    "accuracy = (valid_results['true_label'] == valid_results['llm_pred']).mean()\n",
    "print(f\"\\nLLM Classification Accuracy on Full Test Set: {accuracy:.2f}\")\n",
    "print(confusion_matrix(results_df['true_label'], results_df['llm_pred']))\n",
    "print(classification_report(results_df['true_label'], results_df['llm_pred']))"
   ],
   "id": "3f0d882a8463f0eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Classification Accuracy on Full Test Set: 0.54\n",
      "[[750   0 727]\n",
      " [  0   0   0]\n",
      " [534   1 720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        SAFE       0.58      0.51      0.54      1477\n",
      "     UNKNOWN       0.00      0.00      0.00         0\n",
      "  VULNERABLE       0.50      0.57      0.53      1255\n",
      "\n",
      "    accuracy                           0.54      2732\n",
      "   macro avg       0.36      0.36      0.36      2732\n",
      "weighted avg       0.54      0.54      0.54      2732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arushijain/PycharmProjects/AIPoweredCodeAssistant/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arushijain/PycharmProjects/AIPoweredCodeAssistant/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/arushijain/PycharmProjects/AIPoweredCodeAssistant/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6e6dbd38381ebb04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
