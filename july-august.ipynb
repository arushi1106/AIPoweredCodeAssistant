{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:45:23.318029Z",
     "start_time": "2025-08-01T16:42:44.573856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load dataset (change to test or valid as needed)\n",
    "df = pd.read_csv(\"/Users/arushijain/PycharmProjects/AIPoweredCodeAssistant/datasets/security/test_preprocessed.csv\")\n",
    "\n",
    "# Select a sample to avoid running on full dataset immediately\n",
    "sample_df = df[['id', 'func', 'target']].sample(20, random_state=42)\n",
    "\n",
    "# Store LLM predictions\n",
    "llm_outputs = []\n",
    "\n",
    "# Define the prompt template\n",
    "def create_prompt(code_snippet):\n",
    "    return f\"\"\"\n",
    "You are a security auditor. Analyze the following C code and determine whether it contains any security vulnerabilities (such as buffer overflow, memory leaks, use-after-free, or unsafe pointer manipulation). If yes, explain what they are. If not, state it's safe.\n",
    "\n",
    "Code:\n",
    "{code_snippet}\n",
    "\n",
    "Answer with one of the following:\n",
    "- 'VULNERABLE' and the reason\n",
    "- 'SAFE' and why\n",
    "\"\"\"\n",
    "\n",
    "# Query OpenAI\n",
    "def get_llm_response(prompt):\n",
    "    try:\n",
    "        client = OpenAI(api_key=\"\" )\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature = 0\n",
    "        )\n",
    "        completion = response.choices[0].message.content\n",
    "        return completion\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "# Run LLM over the sample\n",
    "for _, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    code = row['func']\n",
    "    target = row['target']\n",
    "    prompt = create_prompt(code)\n",
    "    response = get_llm_response(prompt)\n",
    "\n",
    "    # Parse response for classification\n",
    "    pred = \"VULNERABLE\" if \"vulnerable\" in response.lower() else \"SAFE\"\n",
    "\n",
    "    llm_outputs.append({\n",
    "        \"id\": row['id'],\n",
    "        \"true_label\": \"VULNERABLE\" if target else \"SAFE\",\n",
    "        \"llm_pred\": pred,\n",
    "        \"response\": response\n",
    "    })\n",
    "\n",
    "# Create result DataFrame\n",
    "results_df = pd.DataFrame(llm_outputs)\n",
    "\n",
    "# Save results for further analysis\n",
    "results_df.to_csv(\"llm_vulnerability_results.csv\", index=False)\n",
    "\n",
    "# Optional: Print accuracy\n",
    "accuracy = (results_df['true_label'] == results_df['llm_pred']).mean()\n",
    "print(f\"\\nLLM Classification Accuracy: {accuracy:.2f}\")\n"
   ],
   "id": "47612cb654a288c0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:38<00:00,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Classification Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T17:21:51.821787Z",
     "start_time": "2025-08-01T17:21:51.746784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(results_df['true_label'], results_df['llm_pred']))\n",
    "print(classification_report(results_df['true_label'], results_df['llm_pred']))"
   ],
   "id": "1a599976006a4f60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 4]\n",
      " [1 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        SAFE       0.90      0.69      0.78        13\n",
      "  VULNERABLE       0.60      0.86      0.71         7\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.75      0.77      0.74        20\n",
      "weighted avg       0.80      0.75      0.76        20\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "505afdde4691a03c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
